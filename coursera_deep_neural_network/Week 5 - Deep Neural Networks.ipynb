{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "infinite-nirvana",
   "metadata": {},
   "source": [
    "# Deep Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-plaintiff",
   "metadata": {},
   "source": [
    "## in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hawaiian-extension",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:01:20.415828Z",
     "start_time": "2021-07-15T12:01:19.967040Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dietary-carolina",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:02:17.981202Z",
     "start_time": "2021-07-15T12:02:17.977915Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, D_in, H1, H2, D_out):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(D_in, H1)\n",
    "        self.linear2 = nn.Linear(H1, H2)\n",
    "        self.linear3 = nn.Linear(H2, D_out)\n",
    "    def forward(self, x):\n",
    "        x=sigmoid(self.linear1(x))       \n",
    "        x=sigmoid(self.linear2(x))\n",
    "        x=self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "verbal-reservation",
   "metadata": {},
   "source": [
    "## using nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dynamic-gender",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:06:00.859830Z",
     "start_time": "2021-07-15T12:06:00.847750Z"
    }
   },
   "outputs": [],
   "source": [
    "input_dim = 2\n",
    "hidden_dim1 = 6\n",
    "hidden_dim2 = 4\n",
    "output_dim = 3\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_dim, hidden_dim1),\n",
    "    nn.Sigmoid(),\n",
    "    nn.Linear(hidden_dim1, hidden_dim2),\n",
    "    nn.Sigmoid(),    \n",
    "    nn.Linear(hidden_dim2, output_dim)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "future-blackberry",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defined-swedish",
   "metadata": {},
   "source": [
    "we create a validation and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "imposed-liberty",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:06:35.672382Z",
     "start_time": "2021-07-15T12:06:35.615694Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "train_dataset = dsets.MNIST(root='./data', train = True, download = True, transform=transforms.ToTensor())\n",
    "validation_dataset = dsets.MNIST(root='./data', train = False, download = True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-hearing",
   "metadata": {},
   "source": [
    "we create a validation and training loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "noticed-owner",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:06:36.462533Z",
     "start_time": "2021-07-15T12:06:36.456776Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000)\n",
    "validation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "independent-weekly",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:06:37.013565Z",
     "start_time": "2021-07-15T12:06:37.007848Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stylish-disposal",
   "metadata": {},
   "source": [
    "we create the training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "physical-airline",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:06:53.124932Z",
     "start_time": "2021-07-15T12:06:53.118061Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, criterion, train_loader, validation_loader, optimizer, epochs=100):\n",
    "    i = 0\n",
    "    useful_stuff = {'training_loss': [],'validation_accuracy': []}  \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        for i, (x, y) in enumerate(train_loader): \n",
    "            optimizer.zero_grad()\n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            loss = criterion(z, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "             #loss for every iteration\n",
    "            useful_stuff['training_loss'].append(loss.data.item())\n",
    "        correct = 0\n",
    "        for x, y in validation_loader:\n",
    "            #validation \n",
    "            z = model(x.view(-1, 28 * 28))\n",
    "            _, label = torch.max(z, 1)\n",
    "            correct += (label == y).sum().item()\n",
    "        accuracy = 100 * (correct / len(validation_dataset))\n",
    "        useful_stuff['validation_accuracy'].append(accuracy)\n",
    "    return useful_stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-peeing",
   "metadata": {},
   "source": [
    "We instantiate and Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "removable-sitting",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:10:50.618320Z",
     "start_time": "2021-07-15T12:08:33.289329Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:17<00:00,  4.58s/it]\n"
     ]
    }
   ],
   "source": [
    "input_dim = 28 * 28\n",
    "hidden_dim1 = 50\n",
    "hidden_dim2 = 50\n",
    "output_dim = 10\n",
    "\n",
    "model = Net(input_dim, hidden_dim1, hidden_dim2, output_dim)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "training_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-burlington",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T10:03:14.748763Z",
     "start_time": "2021-07-15T10:03:14.746139Z"
    }
   },
   "source": [
    "Plot improper classified items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tired-amplifier",
   "metadata": {},
   "source": [
    " # Deep Neural Networks : nn.ModuleList()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-reduction",
   "metadata": {},
   "source": [
    "We create a list called layer,\n",
    "the first element of the list is the feature size; in this case, two.\n",
    "The second element of the list is the number of neurons in the first hidden layer;\n",
    "in this case, three. The third element is the number of neurons in the second hidden layer, which is 4.\n",
    "The fourth element is the number of classes in the output layer, which is three in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "removable-lighter",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:34:03.507751Z",
     "start_time": "2021-07-15T12:34:03.502827Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "integrated-apache",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:36:20.572956Z",
     "start_time": "2021-07-15T12:36:20.567420Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, Layers):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = nn.ModuleList()\n",
    "        for input_size, output_size in zip(Layers, Layers[1:]):\n",
    "            self.hidden.append(nn.Linear(input_size, output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "laughing-pathology",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:36:47.137171Z",
     "start_time": "2021-07-15T12:36:47.131479Z"
    }
   },
   "outputs": [],
   "source": [
    "Layers = [2, 3, 4, 3]\n",
    "model = Net(Layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-basketball",
   "metadata": {},
   "source": [
    " [jdc](https://alexhagen.github.io/jdc/) : Jupyter magic that allows defining classes over multiple jupyter notebook cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "least-filing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:41:56.318700Z",
     "start_time": "2021-07-15T12:41:56.309525Z"
    }
   },
   "outputs": [],
   "source": [
    "import jdc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "environmental-trail",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T12:47:12.827802Z",
     "start_time": "2021-07-15T12:47:12.821824Z"
    }
   },
   "outputs": [],
   "source": [
    "%%add_to Net\n",
    "\n",
    "def forward(self, x):\n",
    "    L = len(self.hidden)\n",
    "    for (l, linear_transform) in zip(range(L), self.hidden):\n",
    "        if (l < L-1):\n",
    "            x = torch.relu(linear_transform(x))\n",
    "        else:\n",
    "            x = linear_transform(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-devil",
   "metadata": {},
   "source": [
    "# Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-eating",
   "metadata": {},
   "source": [
    "## using nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "welsh-terror",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T13:08:00.579146Z",
     "start_time": "2021-07-15T13:08:00.572213Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, in_size, n_hidden, out_size, p=0):\n",
    "        super(Net, self).__init__()\n",
    "        self.drop = nn.Dropout(p=p)\n",
    "        self.linear1 = nn.Linear(in_size, n_hidden)\n",
    "        self.linear2 = nn.Linear(n_hidden, n_hidden)\n",
    "        self.linear3 = nn.Linear(n_hidden, out_size)\n",
    "    def forward(self, x):\n",
    "        x=torch.relu(self.linear1(x))       \n",
    "        x=self.drop(x)\n",
    "        x=torch.relu(self.linear2(x))\n",
    "        x=self.drop(x)\n",
    "        x=self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "comprehensive-wildlife",
   "metadata": {},
   "source": [
    "## using nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "incomplete-orientation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T13:18:00.731922Z",
     "start_time": "2021-07-15T13:18:00.721616Z"
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Linear(1, 10),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(10, 12),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 1),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infinite-establishment",
   "metadata": {},
   "source": [
    "## training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "monetary-stability",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T13:18:01.306138Z",
     "start_time": "2021-07-15T13:18:01.289828Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader \n",
    "import numpy as np\n",
    "# Create data class for creating dataset object\n",
    "\n",
    "class Data(Dataset):\n",
    "    \n",
    "    # Constructor\n",
    "    def __init__(self, N_SAMPLES=1000, noise_std=0.15, train=True):\n",
    "        a = np.matrix([-1, 1, 2, 1, 1, -3, 1]).T\n",
    "        self.x = np.matrix(np.random.rand(N_SAMPLES, 2))\n",
    "        self.f = np.array(a[0] + (self.x) * a[1:3] + np.multiply(self.x[:, 0], self.x[:, 1]) * a[4] + np.multiply(self.x, self.x) * a[5:7]).flatten()\n",
    "        self.a = a\n",
    "       \n",
    "        self.y = np.zeros(N_SAMPLES)\n",
    "        self.y[self.f > 0] = 1\n",
    "        self.y = torch.from_numpy(self.y).type(torch.LongTensor)\n",
    "        self.x = torch.from_numpy(self.x).type(torch.FloatTensor)\n",
    "        self.x = self.x + noise_std * torch.randn(self.x.size())\n",
    "        self.f = torch.from_numpy(self.f)\n",
    "        self.a = a\n",
    "        if train == True:\n",
    "            torch.manual_seed(1)\n",
    "            self.x = self.x + noise_std * torch.randn(self.x.size())\n",
    "            torch.manual_seed(0)\n",
    "        \n",
    "    # Getter        \n",
    "    def __getitem__(self, index):    \n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    # Get Length\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    # Plot the diagram\n",
    "    def plot(self):\n",
    "        X = data_set.x.numpy()\n",
    "        y = data_set.y.numpy()\n",
    "        h = .02\n",
    "        x_min, x_max = X[:, 0].min(), X[:, 0].max()\n",
    "        y_min, y_max = X[:, 1].min(), X[:, 1].max() \n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "        Z = data_set.multi_dim_poly(np.c_[xx.ravel(), yy.ravel()]).flatten()\n",
    "        f = np.zeros(Z.shape)\n",
    "        f[Z > 0] = 1\n",
    "        f = f.reshape(xx.shape)\n",
    "        \n",
    "        plt.title('True decision boundary  and sample points with noise ')\n",
    "        plt.plot(self.x[self.y == 0, 0].numpy(), self.x[self.y == 0,1].numpy(), 'bo', label='y=0') \n",
    "        plt.plot(self.x[self.y == 1, 0].numpy(), self.x[self.y == 1,1].numpy(), 'ro', label='y=1')\n",
    "        plt.contour(xx, yy, f,cmap=plt.cm.Paired)\n",
    "        plt.xlim(0,1)\n",
    "        plt.ylim(0,1)\n",
    "        plt.legend()\n",
    "    \n",
    "    # Make a multidimension ploynomial function\n",
    "    def multi_dim_poly(self, x):\n",
    "        x = np.matrix(x)\n",
    "        out = np.array(self.a[0] + (x) * self.a[1:3] + np.multiply(x[:, 0], x[:, 1]) * self.a[4] + np.multiply(x, x) * self.a[5:7])\n",
    "        out = np.array(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "olympic-argentina",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T13:20:26.810457Z",
     "start_time": "2021-07-15T13:20:26.805017Z"
    }
   },
   "outputs": [],
   "source": [
    "model_drop = Net(2, 300, 2, p=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opponent-relations",
   "metadata": {},
   "source": [
    "**train method** tells the model we are in the training phase which will implement the dropout method, later we use the dot eval method to tell the model it is in the evaluation phase\n",
    "and that will turn off the dropout method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "specialized-developer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T13:20:27.591649Z",
     "start_time": "2021-07-15T13:20:27.584612Z"
    }
   },
   "outputs": [],
   "source": [
    "model_drop.train()\n",
    "optimizer = torch.optim.Adam(model_drop.parameters(), lr = 0.01)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "data_set = Data()\n",
    "validation_set = Data(train=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "least-yeast",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T13:20:28.001439Z",
     "start_time": "2021-07-15T13:20:27.997905Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize the LOSS dictionary to store the loss\n",
    "\n",
    "LOSS = {}\n",
    "LOSS['training data dropout'] = []\n",
    "LOSS['validation data dropout'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fatal-excess",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T13:22:24.381517Z",
     "start_time": "2021-07-15T13:22:22.025199Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:02<00:00, 212.71it/s]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "from tqdm import tqdm\n",
    "\n",
    "epochs = 500\n",
    "\n",
    "def train_model(epochs):\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        #all the samples are used for training \n",
    "        yhat_drop = model_drop(data_set.x)\n",
    "        loss_drop = criterion(yhat_drop, data_set.y)\n",
    "\n",
    "        #store the loss for both the training and validation data for both models \n",
    "        LOSS['training data dropout'].append(loss_drop.item())\n",
    "        model_drop.eval()\n",
    "        LOSS['validation data dropout'].append(criterion(model_drop(validation_set.x), validation_set.y).item())\n",
    "        model_drop.train()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_drop.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "train_model(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "genetic-compilation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T13:23:03.791597Z",
     "start_time": "2021-07-15T13:23:03.785809Z"
    }
   },
   "outputs": [],
   "source": [
    "# The function for calculating accuracy\n",
    "\n",
    "def accuracy(model, data_set):\n",
    "    _, yhat = torch.max(model(data_set.x), 1)\n",
    "    return (yhat == data_set.y).numpy().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "young-cinema",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-15T13:23:04.236637Z",
     "start_time": "2021-07-15T13:23:04.228914Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model with dropout:  0.866\n"
     ]
    }
   ],
   "source": [
    "# Print out the accuracy of the model with dropout\n",
    "\n",
    "print(\"The accuracy of the model with dropout: \", accuracy(model_drop, validation_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-remains",
   "metadata": {},
   "source": [
    "# Neural Network initialization weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forced-hollywood",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
